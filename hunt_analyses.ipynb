{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import ticker\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "input_file_foras = list(Path(os.path.join(\"data\")).glob(\"PTSS_Data_Foras.xlsx\"))[0]\n",
    "input_file_synergy = list(Path(os.path.join(\"data\")).glob(\"PTSS_Data_Synergy.xlsx\"))[0]\n",
    "fulltext_foras = list(Path(os.path.join(\"data\")).glob(\"PTSS_Data_Foras_Fulltext.xlsx\"))[\n",
    "    0\n",
    "]\n",
    "fulltext_foras_2nd = list(\n",
    "    Path(os.path.join(\"data\")).glob(\"PTSS_Data_Foras_Fulltext_2ndscreener.xlsx\")\n",
    ")[0]\n",
    "fulltext_synergy = list(\n",
    "    Path(os.path.join(\"data\")).glob(\"PTSS_Data_Synergy_Fulltext.xlsx\")\n",
    ")[0]\n",
    "\n",
    "# Print the file names\n",
    "print(\n",
    "    \"Results based on file: \",\n",
    "    input_file_foras,\n",
    "    input_file_synergy,\n",
    "    fulltext_foras,\n",
    "    fulltext_foras_2nd,\n",
    "    fulltext_synergy,\n",
    ")\n",
    "\n",
    "# Read the foras file and filter out the duplicates\n",
    "foras_unfiltered = pd.read_excel(input_file_foras)\n",
    "foras_filtered = foras_unfiltered[foras_unfiltered[\"filter_duplicate\"] != 1]\n",
    "\n",
    "# Read the other files\n",
    "synergy = pd.read_excel(input_file_synergy)\n",
    "fulltext_foras = pd.read_excel(fulltext_foras)\n",
    "fulltext_foras_2nd = pd.read_excel(fulltext_foras_2nd)\n",
    "fulltext_synergy = pd.read_excel(fulltext_synergy)\n",
    "\n",
    "# Print the number of rows in each file\n",
    "print(\"Number of records in original FORAS file: \", foras_unfiltered.shape[0])\n",
    "print(\n",
    "    \"Number of records in FORAS after filtering duplicates: \", foras_filtered.shape[0]\n",
    ")\n",
    "print(\"Number of records in SYNERGY\", synergy.shape[0])\n",
    "print(\"Number of records in FORAS fulltext\", fulltext_foras.shape[0])\n",
    "print(\"Number of records in FORAS fulltext 2nd screener\", fulltext_foras_2nd.shape[0])\n",
    "print(\"Number of records in SYNERGY fulltext\", fulltext_synergy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of duplicates in the foras unfiltred file using duplicate_record_identifier\n",
    "duplicates = foras_unfiltered[\n",
    "    foras_unfiltered[\"duplicate_record_identifier\"].notnull()\n",
    "].shape[0]\n",
    "print(\n",
    "    \"Number of duplicates in FORAS file, which will be ignored in the remainder of the analyses: \",\n",
    "    duplicates,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of PIDs, Titles and Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing data and plot for a given dataset\n",
    "def analyze_missing_data(dataset, dataset_name):\n",
    "    # Define columns to check for missing values\n",
    "    columns_to_check = [\"doi\", \"openalex_id\", \"title\", \"abstract\"]\n",
    "    missing_data_counts = {col: dataset[col].isnull().sum() for col in columns_to_check}\n",
    "    missing_data_counts[\"Both Missing\"] = (\n",
    "        dataset[\"doi\"].isnull().sum() & dataset[\"openalex_id\"].isnull().sum()\n",
    "    )\n",
    "\n",
    "    # Print the number of records without certain values\n",
    "    print(f\"Missing Data Analysis for {dataset_name}:\")\n",
    "    for category, count in missing_data_counts.items():\n",
    "        print(f\"  - Number of records without {category}: {count}\")\n",
    "\n",
    "    # Calculate percentages for visualization\n",
    "    total_records = dataset.shape[0]\n",
    "    percentages = {\n",
    "        key: (value / total_records) * 100 for key, value in missing_data_counts.items()\n",
    "    }\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    categories = list(percentages.keys())\n",
    "    values = list(percentages.values())\n",
    "    bars = plt.bar(categories, values, color=plt.cm.tab10(range(len(categories))))\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(f\"Percentage of Missing Data in Each Category ({dataset_name})\")\n",
    "    plt.xlabel(\"Missing Data Category\")\n",
    "    plt.ylabel(\"Percentage of Total Records\")\n",
    "\n",
    "    # Annotate bars\n",
    "    for bar, category in zip(bars, categories):\n",
    "        height = bar.get_height()\n",
    "        count = missing_data_counts[category]\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height,\n",
    "            f\"{count} ({height:.1f}%)\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    # Display the chart\n",
    "    plt.show()\n",
    "\n",
    "    # Return results for further programmatic use\n",
    "    return missing_data_counts\n",
    "\n",
    "\n",
    "# Call the function for both datasets\n",
    "foras_results = analyze_missing_data(foras_filtered, \"Foras\")\n",
    "synergy_results = analyze_missing_data(synergy, \"Synergy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequencies for search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frequency_overview(dataset, variable_list):\n",
    "    print(\"Frequency Overview:\\n\")\n",
    "    for variable in variable_list:\n",
    "        if variable not in dataset.columns:\n",
    "            print(f\"Variable '{variable}' not found in the dataset. Skipping...\\n\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Variable: {variable}\")\n",
    "        value_counts = dataset[variable].value_counts(dropna=False)\n",
    "        total_records = value_counts.sum()\n",
    "        percentages = (value_counts / total_records * 100).round(2)\n",
    "        frequency_table = pd.DataFrame(\n",
    "            {\"Count\": value_counts, \"Percentage\": percentages}\n",
    "        )\n",
    "\n",
    "        print(frequency_table)\n",
    "        print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "# New list of variables to analyze\n",
    "variable_list_additional = [\n",
    "    \"search_replication\",\n",
    "    \"search_comprehensive\",\n",
    "    \"search_snowballing\",\n",
    "    \"search_fulltext\",\n",
    "    \"search_openalex_inlusion_criteria\",\n",
    "    \"search_openalex_inlusion_criteria_long\",\n",
    "    \"search_openalex_logistic\",\n",
    "    \"search_openalex_logistic_long\",\n",
    "    \"search_openalex_all_abstracts\",\n",
    "    \"search_openalex_all_abstracts_long\",\n",
    "    \"batch\",\n",
    "]\n",
    "\n",
    "generate_frequency_overview(foras_filtered, variable_list_additional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequencies for labeling decissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to analyze\n",
    "variable_list = [\n",
    "    \"title_eligible_Bruno\",\n",
    "    \"TI-AB_IC1_Bruno\",\n",
    "    \"TI-AB_IC2_Bruno\",\n",
    "    \"TI-AB_IC3_Bruno\",\n",
    "    \"TI-AB_IC4_Bruno\",\n",
    "    \"TI-AB_final_label_Bruno\",\n",
    "    \"title_eligible_Rutger\",\n",
    "    \"TI_final_label\",\n",
    "    \"TI-AB_final_label_Rutger\",\n",
    "    \"TI-AB_disagreement_human-human\",\n",
    "    \"TI-AB_IC1_LLM\",\n",
    "    \"TI-AB_IC2_LLM\",\n",
    "    \"TI-AB_IC3_LLM\",\n",
    "    \"TI-AB_IC4_LLM\",\n",
    "    \"TI-AB_final_label_LLM\",\n",
    "    \"LLM_re-assessed\",\n",
    "    \"TI-AB_disagreement_human-LLM\",\n",
    "    \"TI-AB_IC1_joint\",\n",
    "    \"TI-AB_IC2_joint\",\n",
    "    \"TI-AB_IC3_joint\",\n",
    "    \"TI-AB_IC4_joint\",\n",
    "    \"TI-AB_IC1_final\",\n",
    "    \"TI-AB_IC2_final\",\n",
    "    \"TI-AB_IC3_final\",\n",
    "    \"TI-AB_IC4_final\",\n",
    "    \"TI-AB_final_label\",\n",
    "    \"full_text_available\",\n",
    "    \"FT_IC1_Bruno\",\n",
    "    \"FT_IC2_Bruno\",\n",
    "    \"FT_IC3_Bruno\",\n",
    "    \"FT_IC4_Bruno\",\n",
    "    \"FT_exlusion_reason_Bruno\",\n",
    "    \"FT_inclusion_Bruno\",\n",
    "    \"FT_inclusion_Rutger\",\n",
    "    \"FT_exlusion_reason_Rutger\",\n",
    "    \"FT_disagreements_Bruno-Rutger\",\n",
    "    \"FT_IC1_joint\",\n",
    "    \"FT_IC2_joint\",\n",
    "    \"FT_IC3_joint\",\n",
    "    \"FT_IC4_joint\",\n",
    "    \"FT_IC1_final\",\n",
    "    \"FT_IC2_final\",\n",
    "    \"FT_IC3_final\",\n",
    "    \"FT_IC4_final\",\n",
    "    \"FT_final_label\",\n",
    "    \"label_included_TIAB\",\n",
    "    \"label_included_FT\",\n",
    "]\n",
    "\n",
    "# Call the function to generate the frequency overview\n",
    "generate_frequency_overview(foras_filtered, variable_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_inclusions(dataset, final_label, label_1, label_2):\n",
    "    # Total count and percentages for inclusions\n",
    "    print(f\"Inclusion Analysis for {final_label}:\\n\")\n",
    "\n",
    "    # Cross-tabulation\n",
    "    print(f\"Cross-tabulation of {label_1} vs {label_2}:\\n\")\n",
    "    crosstab = pd.crosstab(\n",
    "        dataset[label_1], dataset[label_2], margins=True, dropna=True\n",
    "    )\n",
    "    print(crosstab, \"\\n\")\n",
    "\n",
    "    print(f\"Cross-tabulation of {final_label} vs {label_1}:\\n\")\n",
    "    crosstab = pd.crosstab(\n",
    "        dataset[final_label], dataset[label_1], margins=True, dropna=True\n",
    "    )\n",
    "    print(crosstab, \"\\n\")\n",
    "\n",
    "    print(f\"Cross-tabulation of {final_label} vs {label_2}:\\n\")\n",
    "    crosstab = pd.crosstab(\n",
    "        dataset[final_label], dataset[label_2], margins=True, dropna=True\n",
    "    )\n",
    "    print(crosstab, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for title inclusions\n",
    "analyze_inclusions(\n",
    "    foras_filtered, \"TI_final_label\", \"title_eligible_Rutger\", \"title_eligible_Bruno\"\n",
    ")\n",
    "\n",
    "# Call the function for abstract inclusions\n",
    "analyze_inclusions(\n",
    "    foras_filtered,\n",
    "    \"TI-AB_final_label\",\n",
    "    \"TI-AB_final_label_Rutger\",\n",
    "    \"TI-AB_final_label_Bruno\",\n",
    ")\n",
    "\n",
    "# Call the function for full text inclusions\n",
    "analyze_inclusions(\n",
    "    foras_filtered, \"FT_final_label\", \"FT_inclusion_Rutger\", \"FT_inclusion_Bruno\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for ti-ab inclusions criteria 1\n",
    "analyze_inclusions(\n",
    "    foras_filtered, \"TI-AB_IC1_final\", \"TI-AB_IC1_Bruno\", \"TI-AB_IC1_joint\"\n",
    ")\n",
    "\n",
    "# Call the function for ti-ab inclusions criteria 2\n",
    "analyze_inclusions(\n",
    "    foras_filtered, \"TI-AB_IC2_final\", \"TI-AB_IC2_Bruno\", \"TI-AB_IC2_joint\"\n",
    ")\n",
    "\n",
    "# Call the function for ti-ab inclusions criteria 3\n",
    "analyze_inclusions(\n",
    "    foras_filtered, \"TI-AB_IC3_final\", \"TI-AB_IC3_Bruno\", \"TI-AB_IC3_joint\"\n",
    ")\n",
    "\n",
    "# Call the function for ti-ab inclusions criteria 4\n",
    "analyze_inclusions(\n",
    "    foras_filtered, \"TI-AB_IC4_final\", \"TI-AB_IC4_Bruno\", \"TI-AB_IC4_joint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for FT inclusions criteria 1\n",
    "analyze_inclusions(foras_filtered, \"FT_IC1_final\", \"FT_IC1_Bruno\", \"FT_IC1_joint\")\n",
    "\n",
    "# Call the function for FT inclusions criteria 2\n",
    "analyze_inclusions(foras_filtered, \"FT_IC2_final\", \"FT_IC2_Bruno\", \"FT_IC2_joint\")\n",
    "\n",
    "# Call the function for FT inclusions criteria 3\n",
    "analyze_inclusions(foras_filtered, \"FT_IC3_final\", \"FT_IC3_Bruno\", \"FT_IC3_joint\")\n",
    "\n",
    "# Call the function for FT inclusions criteria 4\n",
    "analyze_inclusions(foras_filtered, \"FT_IC4_final\", \"FT_IC4_Bruno\", \"FT_IC4_joint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original binary columns\n",
    "search_columns = [\n",
    "    \"search_replication\",\n",
    "    \"search_comprehensive\",\n",
    "    \"search_snowballing\",\n",
    "    \"search_fulltext\",\n",
    "    \"search_openalex_inlusion_criteria\",\n",
    "    \"search_openalex_inlusion_criteria_long\",\n",
    "    \"search_openalex_logistic\",\n",
    "    \"search_openalex_logistic_long\",\n",
    "    \"search_openalex_all_abstracts\",\n",
    "    \"search_openalex_all_abstracts_long\",\n",
    "]\n",
    "\n",
    "# Shorter names for plotting\n",
    "short_names = {\n",
    "    \"search_replication\": \"Replication\",\n",
    "    \"search_comprehensive\": \"Comprehensive\",\n",
    "    \"search_snowballing\": \"Snowballing\",\n",
    "    \"search_fulltext\": \"Fulltext\",\n",
    "    \"search_openalex_inlusion_criteria\": \"OpenAlex-Inclusion\",\n",
    "    \"search_openalex_inlusion_criteria_long\": \"OpenAlex-Inclusion-Long\",\n",
    "    \"search_openalex_logistic\": \"OpenAlex-Logistic\",\n",
    "    \"search_openalex_logistic_long\": \"OpenAlex-Logistic-Long\",\n",
    "    \"search_openalex_all_abstracts\": \"OpenAlex-All-Abstracts\",\n",
    "    \"search_openalex_all_abstracts_long\": \"OpenAlex-All-Abstracts-Long\",\n",
    "}\n",
    "\n",
    "# Define a color scheme\n",
    "bar_color = \"#009739\"\n",
    "\n",
    "# Calculate counts for each binary column in Foras\n",
    "counts_foras = [foras_filtered[column].sum() for column in search_columns]\n",
    "\n",
    "# Set up the figure and axis\n",
    "plt.figure(figsize=(12, 6))  # Adjust width dynamically for readability\n",
    "bars_foras = plt.bar(short_names.values(), counts_foras, color=bar_color)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Number of Records Found via the Different Search Methods\", fontsize=14)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xlabel(\"Search Method\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Add gridlines for better readability\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Annotate bars with their values\n",
    "for bar in bars_foras:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        yval + 0.05 * max(counts_foras),\n",
    "        f\"{int(yval)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old versus New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'old-school' variable: 1 if any of the specified columns is 1, else 0\n",
    "foras_filtered[\"old-school\"] = (\n",
    "    foras_filtered[[\"search_replication\", \"search_comprehensive\", \"search_snowballing\"]]\n",
    "    .any(axis=1)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Create 'new-school' variable: 1 if any of the specified columns is 1, else 0\n",
    "foras_filtered[\"new-school\"] = (\n",
    "    foras_filtered[\n",
    "        [\n",
    "            \"search_openalex_inlusion_criteria_long\",\n",
    "            \"search_openalex_logistic_long\",\n",
    "            \"search_openalex_all_abstracts_long\",\n",
    "            \"search_fulltext\",\n",
    "        ]\n",
    "    ]\n",
    "    .any(axis=1)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Calculate counts for each category\n",
    "categories = [\n",
    "    \"Old-school\",\n",
    "    \"New-school\",\n",
    "    \"Both old and new\",\n",
    "]\n",
    "counts = [\n",
    "    foras_filtered[\"old-school\"].sum(),\n",
    "    foras_filtered[\"new-school\"].sum(),\n",
    "    foras_filtered[\n",
    "        (foras_filtered[\"old-school\"] == 1) & (foras_filtered[\"new-school\"] == 1)\n",
    "    ].shape[0],\n",
    "]\n",
    "\n",
    "# Print the counts for validation\n",
    "print(\"Total records: \", foras_filtered.shape[0])\n",
    "print(\"Old-school: \", counts[0])\n",
    "print(\"New-school: \", counts[1])\n",
    "print(\"Both: \", counts[2])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))  # Adjusted figure size for better spacing\n",
    "bar_color = \"#009739\"  # Consistent color for inclusion-related metrics\n",
    "bars = plt.bar(categories, counts, color=bar_color)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Number of Records Found via Different Search Methods in Foras\", fontsize=14)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xlabel(\"Search Method\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate labels at 45 degrees for readability\n",
    "\n",
    "# Annotate each bar with its count\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        yval + 0.05 * max(counts),  # Dynamic adjustment for tall bars\n",
    "        f\"{int(yval)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# Add gridlines for easier visualization\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar chart with Unique search results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search columns\n",
    "search_columns = [\n",
    "    \"search_replication\",\n",
    "    \"search_comprehensive\",\n",
    "    \"search_snowballing\",\n",
    "    \"search_fulltext\",\n",
    "    \"search_openalex_inlusion_criteria_long\",\n",
    "    \"search_openalex_logistic_long\",\n",
    "    \"search_openalex_all_abstracts_long\",\n",
    "]\n",
    "\n",
    "# Generate permutation column\n",
    "foras_filtered = foras_filtered.copy()  # Avoid SettingWithCopyWarning\n",
    "foras_filtered[\"permutation\"] = foras_filtered[search_columns].apply(\n",
    "    lambda row: \"\".join(row.values.astype(int).astype(str)), axis=1\n",
    ")\n",
    "\n",
    "# Value counts and aggregation\n",
    "value_counts = foras_filtered[\"permutation\"].value_counts().reset_index()\n",
    "value_counts.columns = [\"permutation\", \"count\"]\n",
    "\n",
    "sum_inclusions = (\n",
    "    foras_filtered.groupby(\"permutation\")[[\"TI-AB_final_label\", \"FT_final_label\"]]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge results\n",
    "result = pd.merge(value_counts, sum_inclusions, on=\"permutation\")\n",
    "\n",
    "# Convert permutation to binary columns\n",
    "for index, col in enumerate(search_columns):\n",
    "    result[col] = result[\"permutation\"].str[index].astype(int)\n",
    "\n",
    "result.drop(columns=\"permutation\", inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "columns_to_move = [\"count\", \"TI-AB_final_label\", \"FT_final_label\"]\n",
    "new_order = [\n",
    "    col for col in result.columns if col not in columns_to_move\n",
    "] + columns_to_move\n",
    "result = result[new_order]\n",
    "\n",
    "# Filter data\n",
    "df_filtered = result[(result[\"count\"] != 0) & (result[\"TI-AB_final_label\"] != 0)].copy()\n",
    "\n",
    "# Combination column\n",
    "df_filtered[\"combination\"] = (\n",
    "    df_filtered[search_columns].astype(str).agg(\"-\".join, axis=1)\n",
    ")\n",
    "\n",
    "# Aggregate data\n",
    "df_relevant_filtered_agg = (\n",
    "    df_filtered.groupby(\"combination\")\n",
    "    .agg(\n",
    "        relevant_count=(\"TI-AB_final_label\", \"sum\"),\n",
    "        **{col: (col, \"sum\") for col in search_columns},\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_relevant_filtered_agg.sort_values(by=\"relevant_count\", ascending=False, inplace=True)\n",
    "\n",
    "# Define conditions with corrections\n",
    "conditions = [\n",
    "    # Uniquely via Snowballing\n",
    "    (df_relevant_filtered_agg[\"search_snowballing\"] == 1)\n",
    "    & (\n",
    "        df_relevant_filtered_agg[\n",
    "            [\n",
    "                \"search_replication\",\n",
    "                \"search_comprehensive\",\n",
    "                \"search_fulltext\",\n",
    "                \"search_openalex_inlusion_criteria_long\",\n",
    "                \"search_openalex_logistic_long\",\n",
    "                \"search_openalex_all_abstracts_long\",\n",
    "            ]\n",
    "        ].sum(axis=1)\n",
    "        == 0\n",
    "    ),\n",
    "    # Unique via Old-School (Replication or Comprehensive)\n",
    "    (\n",
    "        df_relevant_filtered_agg[[\"search_replication\", \"search_comprehensive\"]].sum(\n",
    "            axis=1\n",
    "        )\n",
    "        > 0\n",
    "    )\n",
    "    & (\n",
    "        df_relevant_filtered_agg[\n",
    "            [\n",
    "                \"search_snowballing\",\n",
    "                \"search_fulltext\",\n",
    "                \"search_openalex_inlusion_criteria_long\",\n",
    "                \"search_openalex_logistic_long\",\n",
    "                \"search_openalex_all_abstracts_long\",\n",
    "            ]\n",
    "        ].sum(axis=1)\n",
    "        == 0\n",
    "    ),\n",
    "    # Unique via OpenAlex (Inclusion Criteria, Logistic, All Abstracts)\n",
    "    (\n",
    "        df_relevant_filtered_agg[\n",
    "            [\n",
    "                \"search_openalex_inlusion_criteria_long\",\n",
    "                \"search_openalex_logistic_long\",\n",
    "                \"search_openalex_all_abstracts_long\",\n",
    "            ]\n",
    "        ].sum(axis=1)\n",
    "        > 0\n",
    "    )\n",
    "    & (\n",
    "        df_relevant_filtered_agg[\n",
    "            [\n",
    "                \"search_replication\",\n",
    "                \"search_comprehensive\",\n",
    "                \"search_snowballing\",\n",
    "                \"search_fulltext\",\n",
    "            ]\n",
    "        ].sum(axis=1)\n",
    "        == 0\n",
    "    ),\n",
    "    # Always Found (All methods combined, excluding Fulltext)\n",
    "    (df_relevant_filtered_agg[\"search_fulltext\"] == 0)\n",
    "    & (\n",
    "        df_relevant_filtered_agg[\n",
    "            [\n",
    "                \"search_replication\",\n",
    "                \"search_comprehensive\",\n",
    "                \"search_snowballing\",\n",
    "                \"search_openalex_inlusion_criteria_long\",\n",
    "                \"search_openalex_logistic_long\",\n",
    "                \"search_openalex_all_abstracts_long\",\n",
    "            ]\n",
    "        ].sum(axis=1)\n",
    "        == len(search_columns) - 1\n",
    "    ),\n",
    "    # Unique via Fulltext\n",
    "    (df_relevant_filtered_agg[\"search_fulltext\"] == 1)\n",
    "    & (\n",
    "        df_relevant_filtered_agg[\n",
    "            [\n",
    "                \"search_replication\",\n",
    "                \"search_comprehensive\",\n",
    "                \"search_snowballing\",\n",
    "                \"search_openalex_inlusion_criteria_long\",\n",
    "                \"search_openalex_logistic_long\",\n",
    "                \"search_openalex_all_abstracts_long\",\n",
    "            ]\n",
    "        ].sum(axis=1)\n",
    "        == 0\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Assign colors\n",
    "colors = [\"#ff7f0e\", \"#8B4513\", \"#4682B4\", \"#2ca02c\", \"#ffcc00\", \"#d3d3d3\"]\n",
    "df_relevant_filtered_agg[\"color\"] = np.select(\n",
    "    conditions, colors[:-1], default=colors[-1]\n",
    ")\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(14, 10))\n",
    "bars = plt.bar(\n",
    "    df_relevant_filtered_agg[\"combination\"],\n",
    "    df_relevant_filtered_agg[\"relevant_count\"],\n",
    "    color=df_relevant_filtered_agg[\"color\"],\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    \"Overview of Included Records per Combination of Search Strategies\", fontsize=14\n",
    ")\n",
    "plt.xlabel(\"Combination\", fontsize=12)\n",
    "plt.ylabel(\"Relevant Count\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Dynamic legend with k= and italicized k\n",
    "condition_counts = df_relevant_filtered_agg.groupby(\"color\")[\"relevant_count\"].sum()\n",
    "legend_labels = [\n",
    "    f\"{label} $k={int(condition_counts.get(color, 0))}$\"\n",
    "    for label, color in zip(\n",
    "        [\n",
    "            \"Uniquely via Snowballing\",\n",
    "            \"Unique via Old-School\",\n",
    "            \"Unique via OpenAlex\",\n",
    "            \"Always Found\",\n",
    "            \"Unique via Fulltext\",\n",
    "            \"Other Cases\",\n",
    "        ],\n",
    "        colors,\n",
    "    )\n",
    "]\n",
    "handles = [\n",
    "    plt.Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=color, markersize=10)\n",
    "    for color in colors\n",
    "]\n",
    "plt.legend(\n",
    "    handles,\n",
    "    legend_labels,\n",
    "    title=\"Conditions\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    ")\n",
    "\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Add bullet list\n",
    "datasets = [\n",
    "    \"x...... Replication\",\n",
    "    \".x..... Comprehensive\",\n",
    "    \"..x.... Snowballing\",\n",
    "    \"...x... Fulltext\",\n",
    "    \"....x.. Inclusion Criteria\",\n",
    "    \".....x. Logistic\",\n",
    "    \"......x All Abstracts\",\n",
    "]\n",
    "plt.text(\n",
    "    0.8,\n",
    "    0.1,\n",
    "    \"Order of Datasets:\\n\" + \"\\n\".join(f\"â€¢ {dataset}\" for dataset in datasets),\n",
    "    horizontalalignment=\"left\",\n",
    "    verticalalignment=\"center\",\n",
    "    transform=plt.gcf().transFigure,\n",
    "    bbox=dict(facecolor=\"none\", edgecolor=\"black\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total relevant count\n",
    "total_relevant_count = df_relevant_filtered_agg[\"relevant_count\"].sum()\n",
    "\n",
    "# Calculate total number of records uniquely identified with only one search strategy\n",
    "unique_single_strategy_count = df_relevant_filtered_agg[\n",
    "    (df_relevant_filtered_agg[search_columns].sum(axis=1) == 1)\n",
    "][\"relevant_count\"].sum()\n",
    "unique_single_strategy_percentage = (\n",
    "    unique_single_strategy_count / total_relevant_count\n",
    ") * 100\n",
    "print(\n",
    "    f\"Total number of records uniquely identified with only one search strategy: {unique_single_strategy_count}\"\n",
    ")\n",
    "print(\n",
    "    f\"Percentage of records uniquely identified with only one search strategy: {unique_single_strategy_percentage:.2f}%\"\n",
    ")\n",
    "\n",
    "# Calculate number and percentage of other cases\n",
    "other_cases_count = df_relevant_filtered_agg[\n",
    "    df_relevant_filtered_agg[\"color\"] == \"#d3d3d3\"\n",
    "][\"relevant_count\"].sum()\n",
    "other_cases_percentage = (other_cases_count / total_relevant_count) * 100\n",
    "print(f\"Number of other cases: {other_cases_count}\")\n",
    "print(f\"Percentage of other cases: {other_cases_percentage:.2f}%\")\n",
    "\n",
    "# Calculate total number of records minus other cases\n",
    "minus_other_cases_count = total_relevant_count - other_cases_count\n",
    "minus_other_cases_percentage = (minus_other_cases_count / total_relevant_count) * 100\n",
    "print(f\"Total number of records minus other cases: {minus_other_cases_count}\")\n",
    "print(f\"Percentage of records minus other cases: {minus_other_cases_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pie chart with Ti-Ab inclusions for Foras and Synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to format autopct values with decimals and commas\n",
    "def autopct_format(values):\n",
    "    def inner_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = round(pct * total / 100.0)\n",
    "        if val > 999:\n",
    "            val_str = f\"{val:,.0f}\"  # Format with commas for large numbers\n",
    "        else:\n",
    "            val_str = f\"{val}\"\n",
    "        return f\"{val_str} ({pct:.1f}%)\"\n",
    "\n",
    "    return inner_autopct\n",
    "\n",
    "\n",
    "# Function to create a pie chart with left-aligned text for included values\n",
    "def plot_pie_chart(data, title, subplot_position, labels):\n",
    "    plt.subplot(1, 3, subplot_position)\n",
    "    wedges, texts, autotexts = plt.pie(\n",
    "        data,\n",
    "        labels=labels,\n",
    "        colors=brazilian_colors,\n",
    "        autopct=autopct_format(data),\n",
    "        startangle=90,\n",
    "    )\n",
    "    plt.title(f\"{title}\\nTotal: {data.sum():,}\", loc=\"center\")\n",
    "\n",
    "    # Adjust alignment for included values\n",
    "    for i, (autotext, wedge) in enumerate(zip(autotexts, wedges)):\n",
    "        if labels[i] == \"Included\":\n",
    "            autotext.set_horizontalalignment(\"right\")\n",
    "        else:\n",
    "            autotext.set_horizontalalignment(\"center\")\n",
    "\n",
    "\n",
    "# Brazilian flag colors\n",
    "brazilian_colors = [\n",
    "    \"#FEDD00\",  # yellow\n",
    "    \"#009739\",  # green\n",
    "]\n",
    "\n",
    "# Data preparation\n",
    "foras_tiab_records = foras_filtered[\"label_included_TIAB\"].value_counts()\n",
    "synergy_tiab_records = synergy[\"TI-AB-corrected\"].value_counts()\n",
    "combined_tiab_records = foras_tiab_records.add(synergy_tiab_records, fill_value=0)\n",
    "\n",
    "# Plot setup\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplots_adjust(right=0.85)\n",
    "\n",
    "# Plotting\n",
    "plot_pie_chart(foras_tiab_records, \"FORAS TI-AB\", 1, [\"Excluded\", \"Included\"])\n",
    "plot_pie_chart(synergy_tiab_records, \"Synergy TI-AB\", 2, [\"Excluded\", \"Included\"])\n",
    "plot_pie_chart(combined_tiab_records, \"Total TI-AB\", 3, [\"Excluded\", \"Included\"])\n",
    "\n",
    "# Legend\n",
    "plt.legend(\n",
    "    [\"Excluded\", \"Included\"], loc=\"center left\", bbox_to_anchor=(1, 0.5), frameon=False\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pie chart with FT inclusions for Foras and Synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation for FT labels\n",
    "foras_ft_records = foras_filtered[\"label_included_FT\"].value_counts()\n",
    "synergy_ft_records = synergy[\"FT-corrected\"].value_counts()\n",
    "combined_ft_records = foras_ft_records.add(synergy_ft_records, fill_value=0)\n",
    "\n",
    "# Plot setup for FT labels\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplots_adjust(right=0.85)\n",
    "\n",
    "# Plotting for FT labels\n",
    "plot_pie_chart(foras_ft_records, \"FORAS FT\", 1, labels=[\"Excluded\", \"Included\"])\n",
    "plot_pie_chart(synergy_ft_records, \"Synergy FT\", 2, labels=[\"Excluded\", \"Included\"])\n",
    "plot_pie_chart(combined_ft_records, \"Total FT\", 3, labels=[\"Excluded\", \"Included\"])\n",
    "\n",
    "# Legend\n",
    "plt.legend(\n",
    "    [\"Excluded\", \"Included\"], loc=\"center left\", bbox_to_anchor=(1, 0.5), frameon=False\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

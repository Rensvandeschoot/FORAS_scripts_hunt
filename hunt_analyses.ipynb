{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "input_file_foras = list(Path(os.path.join(\"data\")).glob(\"PTSS_Data_Foras.xlsx\"))[0]\n",
    "input_file_synergy = list(Path(os.path.join(\"data\")).glob(\"PTSS_Data_Synergy.xlsx\"))[0]\n",
    "fulltext_foras = list(Path(os.path.join(\"data\")).glob(\"PTSS_Data_Foras_Fulltext.xlsx\"))[\n",
    "    0\n",
    "]\n",
    "fulltext_foras_2nd = list(\n",
    "    Path(os.path.join(\"data\")).glob(\"PTSS_Data_Foras_Fulltext_2ndscreener.xlsx\")\n",
    ")[0]\n",
    "fulltext_synergy = list(\n",
    "    Path(os.path.join(\"data\")).glob(\"PTSS_Data_Synergy_Fulltext.xlsx\")\n",
    ")[0]\n",
    "\n",
    "# Print the file names\n",
    "print(\n",
    "    \"Results based on file: \",\n",
    "    input_file_foras,\n",
    "    input_file_synergy,\n",
    "    fulltext_foras,\n",
    "    fulltext_foras_2nd,\n",
    "    fulltext_synergy,\n",
    ")\n",
    "\n",
    "# Read the foras file and filter out the duplicates\n",
    "foras_unfiltered = pd.read_excel(input_file_foras)\n",
    "foras_filtered = foras_unfiltered[foras_unfiltered[\"filter_duplicate\"] != 1]\n",
    "\n",
    "# Read the other files\n",
    "synergy = pd.read_excel(input_file_synergy)\n",
    "fulltext_foras = pd.read_excel(fulltext_foras)\n",
    "fulltext_foras_2nd = pd.read_excel(fulltext_foras_2nd)\n",
    "fulltext_synergy = pd.read_excel(fulltext_synergy)\n",
    "\n",
    "# Print the number of rows in each file\n",
    "print(\"Number of records in original FORAS file: \", foras_unfiltered.shape[0])\n",
    "print(\n",
    "    \"Number of records in FORAS after filtering duplicates: \", foras_filtered.shape[0]\n",
    ")\n",
    "print(\"Number of records in SYNERGY\", synergy.shape[0])\n",
    "print(\"Number of records in FORAS fulltext\", fulltext_foras.shape[0])\n",
    "print(\"Number of records in FORAS fulltext 2nd screener\", fulltext_foras_2nd.shape[0])\n",
    "print(\"Number of records in SYNERGY fulltext\", fulltext_synergy.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of duplicates in the foras unfiltred file using duplicate_record_identifier\n",
    "duplicates = foras_unfiltered[\n",
    "    foras_unfiltered[\"duplicate_record_identifier\"].notnull()\n",
    "].shape[0]\n",
    "print(\n",
    "    \"Number of duplicates in FORAS file, which will be ignored in the remainder of the analyses: \",\n",
    "    duplicates,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of PIDs, Titles and Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing data and plot for a given dataset\n",
    "def analyze_missing_data(dataset, dataset_name):\n",
    "    # Define columns to check for missing values\n",
    "    columns_to_check = [\"doi\", \"openalex_id\", \"title\", \"abstract\"]\n",
    "    missing_data_counts = {col: dataset[col].isnull().sum() for col in columns_to_check}\n",
    "    missing_data_counts[\"Both Missing\"] = (\n",
    "        dataset[\"doi\"].isnull().sum() & dataset[\"openalex_id\"].isnull().sum()\n",
    "    )\n",
    "\n",
    "    # Print the number of records without certain values\n",
    "    print(f\"Missing Data Analysis for {dataset_name}:\")\n",
    "    for category, count in missing_data_counts.items():\n",
    "        print(f\"  - Number of records without {category}: {count}\")\n",
    "\n",
    "    # Calculate percentages for visualization\n",
    "    total_records = dataset.shape[0]\n",
    "    percentages = {\n",
    "        key: (value / total_records) * 100 for key, value in missing_data_counts.items()\n",
    "    }\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    categories = list(percentages.keys())\n",
    "    values = list(percentages.values())\n",
    "    bars = plt.bar(categories, values, color=plt.cm.tab10(range(len(categories))))\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(f\"Percentage of Missing Data in Each Category ({dataset_name})\")\n",
    "    plt.xlabel(\"Missing Data Category\")\n",
    "    plt.ylabel(\"Percentage of Total Records\")\n",
    "\n",
    "    # Annotate bars\n",
    "    for bar, category in zip(bars, categories):\n",
    "        height = bar.get_height()\n",
    "        count = missing_data_counts[category]\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height,\n",
    "            f\"{count} ({height:.1f}%)\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    # Display the chart\n",
    "    plt.show()\n",
    "\n",
    "    # Return results for further programmatic use\n",
    "    return missing_data_counts\n",
    "\n",
    "\n",
    "# Call the function for both datasets\n",
    "foras_results = analyze_missing_data(foras_filtered, \"Foras\")\n",
    "synergy_results = analyze_missing_data(synergy, \"Synergy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequencies for search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frequency_overview(dataset, variable_list):\n",
    "    print(\"Frequency Overview:\\n\")\n",
    "    for variable in variable_list:\n",
    "        if variable not in dataset.columns:\n",
    "            print(f\"Variable '{variable}' not found in the dataset. Skipping...\\n\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Variable: {variable}\")\n",
    "        value_counts = dataset[variable].value_counts(dropna=False)\n",
    "        total_records = value_counts.sum()\n",
    "        percentages = (value_counts / total_records * 100).round(2)\n",
    "        frequency_table = pd.DataFrame(\n",
    "            {\"Count\": value_counts, \"Percentage\": percentages}\n",
    "        )\n",
    "\n",
    "        print(frequency_table)\n",
    "        print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "# New list of variables to analyze\n",
    "variable_list_additional = [\n",
    "    \"search_replication\",\n",
    "    \"search_comprehensive\",\n",
    "    \"search_snowballing\",\n",
    "    \"search_fulltext\",\n",
    "    \"openalex_rank_inclusion_criteria\",\n",
    "    \"search_openalex_inlusion_criteria\",\n",
    "    \"search_openalex_inlusion_criteria_long\",\n",
    "    \"openalex_rank_logistic\",\n",
    "    \"search_openalex_logistic\",\n",
    "    \"search_openalex_logistic_long\",\n",
    "    \"openalex_rank_all_abstracts\",\n",
    "    \"openalex_rank_all_abstracts_long\",\n",
    "    \"batch\",\n",
    "]\n",
    "\n",
    "generate_frequency_overview(foras_filtered, variable_list_additional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequencies for labeling decissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to analyze\n",
    "variable_list = [\n",
    "    \"title_eligible_Bruno\",\n",
    "    \"TI-AB_IC1_Bruno\",\n",
    "    \"TI-AB_IC2_Bruno\",\n",
    "    \"TI-AB_IC3_Bruno\",\n",
    "    \"TI-AB_IC4_Bruno\",\n",
    "    \"TI-AB_final_label_Bruno\",\n",
    "    \"title_eligible_Rutger\",\n",
    "    \"TI_final_label\",\n",
    "    \"TI-AB_final_label_Rutger\",\n",
    "    \"TI-AB_disagreement_human-human\",\n",
    "    \"TI-AB_IC1_LLM\",\n",
    "    \"TI-AB_IC2_LLM\",\n",
    "    \"TI-AB_IC3_LLM\",\n",
    "    \"TI-AB_IC4_LLM\",\n",
    "    \"TI-AB_final_label_LLM\",\n",
    "    \"LLM_re-assessed\",\n",
    "    \"TI-AB_disagreement_human-LLM\",\n",
    "    \"TI-AB_IC1_joint\",\n",
    "    \"TI-AB_IC2_joint\",\n",
    "    \"TI-AB_IC3_joint\",\n",
    "    \"TI-AB_IC4_joint\",\n",
    "    \"TI-AB_IC1_final\",\n",
    "    \"TI-AB_IC2_final\",\n",
    "    \"TI-AB_IC3_final\",\n",
    "    \"TI-AB_IC4_final\",\n",
    "    \"TI-AB_final_label\",\n",
    "    \"full_text_available\",\n",
    "    \"FT_IC1_Bruno\",\n",
    "    \"FT_IC2_Bruno\",\n",
    "    \"FT_IC3_Bruno\",\n",
    "    \"FT_IC4_Bruno\",\n",
    "    \"FT_exlusion_reason_Bruno\",\n",
    "    \"FT_inclusion_Bruno\",\n",
    "    \"FT_inclusion_Rutger\",\n",
    "    \"FT_exlusion_reason_Rutger\",\n",
    "    \"FT_disagreements_Bruno-Rutger\",\n",
    "    \"FT_IC1_joint\",\n",
    "    \"FT_IC2_joint\",\n",
    "    \"FT_IC3_joint\",\n",
    "    \"FT_IC4_joint\",\n",
    "    \"FT_IC1_final\",\n",
    "    \"FT_IC2_final\",\n",
    "    \"FT_IC3_final\",\n",
    "    \"FT_IC4_final\",\n",
    "    \"FT_final_label\",\n",
    "    \"label_included_TIAB\",\n",
    "    \"label_included_FT\",\n",
    "]\n",
    "\n",
    "# Call the function to generate the frequency overview\n",
    "generate_frequency_overview(foras_filtered, variable_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_inclusions(dataset, column_label, col1, col2):\n",
    "    # Total count and percentages for title inclusions\n",
    "    print(f\"Inclusion Analysis for {column_label}:\\n\")\n",
    "    value_counts = dataset[column_label].value_counts(dropna=False)\n",
    "    total_records = value_counts.sum()\n",
    "    percentages = (value_counts / total_records * 100).round(2)\n",
    "\n",
    "    print(\"Counts:\")\n",
    "    print(value_counts)\n",
    "    print(\"\\nPercentages:\")\n",
    "    print(percentages)\n",
    "    print(f\"\\nGrand Total: {total_records}\\n\")\n",
    "\n",
    "    # Cross-tabulation\n",
    "    print(f\"Cross-tabulation of {col1} vs {col2}:\\n\")\n",
    "    crosstab = pd.crosstab(dataset[col1], dataset[col2], margins=True, dropna=True)\n",
    "    print(crosstab, \"\\n\")\n",
    "\n",
    "    # Add percentages to the crosstab\n",
    "    print(\"Cross-tabulation with Percentages:\\n\")\n",
    "    crosstab_percentages = crosstab.div(crosstab.loc[\"All\"], axis=1).round(2) * 100\n",
    "    print(crosstab_percentages, \"\\n\")\n",
    "\n",
    "\n",
    "# Call the function for analysis\n",
    "analyze_inclusions(\n",
    "    foras_filtered, \"TI_final_label\", \"title_eligible_Rutger\", \"title_eligible_Bruno\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for analysis\n",
    "analyze_inclusions(\n",
    "    foras_filtered,\n",
    "    \"TI-AB_final_label\",\n",
    "    \"TI-AB_final_label_Rutger\",\n",
    "    \"TI-AB_final_label_Bruno\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for analysis\n",
    "analyze_inclusions(\n",
    "    foras_filtered, \"FT_final_label\", \"FT_inclusion_Rutger\", \"FT_inclusion_Bruno\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

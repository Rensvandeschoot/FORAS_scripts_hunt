{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "input_file_foras = list(Path(os.path.join(\"data\")).glob(\"PTSS_Data_Foras.xlsx\"))[0]\n",
    "input_file_synergy = list(Path(os.path.join(\"data\")).glob(\"PTSS_Data_Synergy.xlsx\"))[0]\n",
    "fulltext_foras = list(Path(os.path.join(\"data\")).glob(\"PTSS_Data_Foras_Fulltext.xlsx\"))[\n",
    "    0\n",
    "]\n",
    "fulltext_synergy = list(\n",
    "    Path(os.path.join(\"data\")).glob(\"PTSS_Data_Synergy_Fulltext.xlsx\")\n",
    ")[0]\n",
    "\n",
    "# Print the file names\n",
    "print(\n",
    "    \"Results based on file: \",\n",
    "    input_file_foras,\n",
    "    input_file_synergy,\n",
    "    fulltext_foras,\n",
    "    fulltext_synergy,\n",
    ")\n",
    "\n",
    "# Read the foras file and filter out the duplicates\n",
    "foras_unfiltered = pd.read_excel(input_file_foras)\n",
    "foras_filtered = foras_unfiltered[foras_unfiltered[\"filter_duplicate\"] != 1]\n",
    "\n",
    "# Read the other files\n",
    "synergy = pd.read_excel(input_file_synergy)\n",
    "fulltext_foras = pd.read_excel(fulltext_foras)\n",
    "fulltext_synergy = pd.read_excel(fulltext_synergy)\n",
    "\n",
    "# Print the number of rows in each file\n",
    "print(\"Number of records in original FORAS file: \", foras_unfiltered.shape[0])\n",
    "print(\n",
    "    \"Number of records in FORAS after filtering duplicates: \", foras_filtered.shape[0]\n",
    ")\n",
    "print(\"Number of records in SYNERGY\", synergy.shape[0])\n",
    "print(\"Number of records in FORAS fulltext\", fulltext_foras.shape[0])\n",
    "print(\"Number of records in SYNERGY fulltext\", fulltext_synergy.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorter names for plotting\n",
    "short_names = {\n",
    "    \"search_replication\": \"Replication\",\n",
    "    \"search_comprehensive\": \"Comprehensive\",\n",
    "    \"search_snowballing\": \"Snowballing\",\n",
    "    \"search_fulltext\": \"Fulltext\",\n",
    "    \"search_openalex_inlusion_criteria\": \"OpenAlex-short: Inclusion Criteria\",\n",
    "    \"search_openalex_inlusion_criteria_long\": \"OpenAlex: Inclusion Criteria\",\n",
    "    \"search_openalex_logistic\": \"OpenAlex-short: Logistic\",\n",
    "    \"search_openalex_logistic_long\": \"OpenAlex: Logistic\",\n",
    "    \"search_openalex_all_abstracts\": \"OpenAlex-short: All Abstracts\",\n",
    "    \"search_openalex_all_abstracts_long\": \"OpenAlex: All Abstracts\",\n",
    "}\n",
    "\n",
    "# binary columns\n",
    "binary_columns = [\n",
    "    \"search_replication\",\n",
    "    \"search_comprehensive\",\n",
    "    \"search_snowballing\",\n",
    "    \"search_fulltext\",\n",
    "    \"search_openalex_inlusion_criteria\",\n",
    "    \"search_openalex_inlusion_criteria_long\",\n",
    "    \"search_openalex_logistic\",\n",
    "    \"search_openalex_logistic_long\",\n",
    "    \"search_openalex_all_abstracts\",\n",
    "    \"search_openalex_all_abstracts_long\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if MID is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of records without an 'MID' value for both datasets\n",
    "num_records_without_mid_foras = foras_filtered[\"MID\"].isnull().sum()\n",
    "num_records_without_mid_synergy = synergy[\"MID\"].isnull().sum()\n",
    "\n",
    "# Calculate the number of duplicate IDs for both datasets\n",
    "num_duplicate_ids_foras = len(foras_filtered[\"MID\"]) - foras_filtered[\"MID\"].nunique()\n",
    "num_duplicate_ids_synergy = len(synergy[\"MID\"]) - synergy[\"MID\"].nunique()\n",
    "\n",
    "# Test for Foras dataset\n",
    "try:\n",
    "    # Check if there are no records without an identifier in the 'MID' column for Foras\n",
    "    assert (\n",
    "        foras_filtered[\"MID\"].notnull().all()\n",
    "    ), f\"Foras test failed: There are {num_records_without_mid_foras} records without an identifier in the 'MID' column.\"\n",
    "\n",
    "    # Check if the identifiers in the 'MID' column are unique for Foras\n",
    "    assert (\n",
    "        foras_filtered[\"MID\"].nunique() == len(foras_filtered[\"MID\"])\n",
    "    ), f\"Foras test failed: There are {num_duplicate_ids_foras} duplicate identifiers in the 'MID' column.\"\n",
    "\n",
    "    # If the test passes for Foras, print the following\n",
    "    print(\n",
    "        \"Foras test passed: 'MID' column contains no records without an identifier and all identifiers are unique.\"\n",
    "    )\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "\n",
    "# Test for Synergy dataset\n",
    "try:\n",
    "    # Check if there are no records without an identifier in the 'MID' column for Synergy\n",
    "    assert (\n",
    "        synergy[\"MID\"].notnull().all()\n",
    "    ), f\"Synergy test failed: There are {num_records_without_mid_synergy} records without an identifier in the 'MID' column.\"\n",
    "\n",
    "    # Check if the identifiers in the 'MID' column are unique for Synergy\n",
    "    assert (\n",
    "        synergy[\"MID\"].nunique() == len(synergy[\"MID\"])\n",
    "    ), f\"Synergy test failed: There are {num_duplicate_ids_synergy} duplicate identifiers in the 'MID' column.\"\n",
    "\n",
    "    # If the test passes for Synergy, print the following\n",
    "    print(\n",
    "        \"Synergy test passed: 'MID' column contains no records without an identifier and all identifiers are unique.\"\n",
    "    )\n",
    "except AssertionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if PIDs, Titles and Abstracts are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing data and plot for a given dataset\n",
    "def analyze_missing_data(dataset, dataset_name):\n",
    "    # Calculate the number of records with missing values for specified columns\n",
    "    num_records_without_doi = dataset[\"doi\"].isnull().sum()\n",
    "    num_records_without_openalex_id = dataset[\"openalex_id\"].isnull().sum()\n",
    "    num_records_without_both = dataset[\n",
    "        dataset[\"doi\"].isnull() & dataset[\"openalex_id\"].isnull()\n",
    "    ].shape[0]\n",
    "    num_records_without_title = dataset[\"title\"].isnull().sum()\n",
    "    num_records_without_abstract = dataset[\"abstract\"].isnull().sum()\n",
    "\n",
    "    # Print the number of records without certain values\n",
    "    print(\n",
    "        f\"{dataset_name} - Number of records without a DOI: {num_records_without_doi}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{dataset_name} - Number of records without an OpenAlex ID: {num_records_without_openalex_id}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{dataset_name} - Number of records without a Title: {num_records_without_title}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{dataset_name} - Number of records without an Abstract: {num_records_without_abstract}\"\n",
    "    )\n",
    "\n",
    "    # Data for plotting\n",
    "    categories = [\n",
    "        \"DOI Missing\",\n",
    "        \"OpenAlex ID Missing\",\n",
    "        \"Both Missing\",\n",
    "        \"Title Missing\",\n",
    "        \"Abstract Missing\",\n",
    "    ]\n",
    "    values = [\n",
    "        num_records_without_doi,\n",
    "        num_records_without_openalex_id,\n",
    "        num_records_without_both,\n",
    "        num_records_without_title,\n",
    "        num_records_without_abstract,\n",
    "    ]\n",
    "    total_records = dataset.shape[0]\n",
    "    percentages = [(value / total_records) * 100 for value in values]\n",
    "\n",
    "    # Creating the bar chart with percentages\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(\n",
    "        categories, percentages, color=[\"blue\", \"orange\", \"green\", \"purple\", \"pink\"]\n",
    "    )\n",
    "\n",
    "    # Adding title and labels for visualization\n",
    "    plt.title(f\"Percentage of Missing Data in Each Category ({dataset_name})\")\n",
    "    plt.xlabel(\"Missing Data Category\")\n",
    "    plt.ylabel(\"Percentage of Total Records\")\n",
    "\n",
    "    # Annotate each bar with its absolute value\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height,\n",
    "            f\"{value}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    # Display the chart\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the function for both datasets\n",
    "analyze_missing_data(foras_filtered, \"Foras\")\n",
    "analyze_missing_data(synergy, \"Synergy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if search columns are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all records in binary columns contain only 0 or 1\n",
    "try:\n",
    "    invalid_binary_values = foras_unfiltered.loc[\n",
    "        ~foras_unfiltered[binary_columns].isin([0, 1]).all(axis=1), \"MID\"\n",
    "    ]\n",
    "    assert (\n",
    "        invalid_binary_values.empty\n",
    "    ), f\"Invalid values in binary columns for MIDs: {invalid_binary_values.tolist()}\"\n",
    "\n",
    "    print(\"All values in search columns are 0 or 1.\")\n",
    "\n",
    "except AssertionError as e:\n",
    "    print(e)\n",
    "\n",
    "# # Check if each record has at least one '1' in binary columns\n",
    "try:\n",
    "    records_with_no_one = foras_unfiltered.loc[\n",
    "        (foras_unfiltered[binary_columns].sum(axis=1) == 0), \"MID\"\n",
    "    ]\n",
    "    assert (\n",
    "        records_with_no_one.empty\n",
    "    ), f\"Records with no '1' in binary columns for MIDs: {records_with_no_one.tolist()}\"\n",
    "\n",
    "    print(\n",
    "        \"All records in the search columns have at least one '1'.\"\n",
    "    )\n",
    "\n",
    "except AssertionError as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
